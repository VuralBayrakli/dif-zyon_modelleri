{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c073166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VuralBayrakli\\gan\\stylegan2-ada-pytorch\n"
     ]
    }
   ],
   "source": [
    "%cd stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7120b040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%cd..` not found.\n"
     ]
    }
   ],
   "source": [
    "%cd.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75fab619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: dataset_tool.py [OPTIONS]\n",
      "\n",
      "  Convert an image dataset into a dataset archive usable with StyleGAN2 ADA\n",
      "  PyTorch.\n",
      "\n",
      "  The input dataset format is guessed from the --source argument:\n",
      "\n",
      "  --source *_lmdb/                    Load LSUN dataset\n",
      "  --source cifar-10-python.tar.gz     Load CIFAR-10 dataset\n",
      "  --source train-images-idx3-ubyte.gz Load MNIST dataset\n",
      "  --source path/                      Recursively load all images from path/\n",
      "  --source dataset.zip                Recursively load all images from dataset.zip\n",
      "\n",
      "  Specifying the output format and path:\n",
      "\n",
      "  --dest /path/to/dir                 Save output files under /path/to/dir\n",
      "  --dest /path/to/dataset.zip         Save output files into /path/to/dataset.zip\n",
      "\n",
      "  The output dataset format can be either an image folder or an uncompressed\n",
      "  zip archive. Zip archives makes it easier to move datasets around file\n",
      "  servers and clusters, and may offer better training performance on network\n",
      "  file systems.\n",
      "\n",
      "  Images within the dataset archive will be stored as uncompressed PNG.\n",
      "  Uncompresed PNGs can be efficiently decoded in the training loop.\n",
      "\n",
      "  Class labels are stored in a file called 'dataset.json' that is stored at\n",
      "  the dataset root folder.  This file has the following structure:\n",
      "\n",
      "  {\n",
      "      \"labels\": [\n",
      "          [\"00000/img00000000.png\",6],\n",
      "          [\"00000/img00000001.png\",9],\n",
      "          ... repeated for every image in the datase\n",
      "          [\"00049/img00049999.png\",1]\n",
      "      ]\n",
      "  }\n",
      "\n",
      "  If the 'dataset.json' file cannot be found, the dataset is interpreted as\n",
      "  not containing class labels.\n",
      "\n",
      "  Image scale/crop and resolution requirements:\n",
      "\n",
      "  Output images must be square-shaped and they must all have the same power-\n",
      "  of-two dimensions.\n",
      "\n",
      "  To scale arbitrary input image size to a specific width and height, use the\n",
      "  --width and --height options.  Output resolution will be either the original\n",
      "  input resolution (if --width/--height was not specified) or the one\n",
      "  specified with --width/height.\n",
      "\n",
      "  Use the --transform=center-crop or --transform=center-crop-wide options to\n",
      "  apply a center crop transform on the input image.  These options should be\n",
      "  used with the --width and --height options.  For example:\n",
      "\n",
      "  python dataset_tool.py --source LSUN/raw/cat_lmdb --dest /tmp/lsun_cat \\\n",
      "      --transform=center-crop-wide --width 512 --height=384\n",
      "\n",
      "Options:\n",
      "  --source PATH                   Directory or archive name for input dataset\n",
      "                                  [required]\n",
      "  --dest PATH                     Output directory or archive name for output\n",
      "                                  dataset  [required]\n",
      "  --max-images INTEGER            Output only up to `max-images` images\n",
      "  --resize-filter [box|lanczos]   Filter to use when resizing images for\n",
      "                                  output resolution  [default: lanczos]\n",
      "  --transform [center-crop|center-crop-wide]\n",
      "                                  Input crop/resize mode\n",
      "  --width INTEGER                 Output width\n",
      "  --height INTEGER                Output height\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!python dataset_tool.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ce191c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"labels\": [\n",
      "        [\n",
      "            \"smoke\\\\frame_vid6_0.jpg\",\n",
      "            0\n",
      "        ],\n",
      "        [\n",
      "            \"smoke\\\\frame_vid6_120.jpg\",\n",
      "            0\n",
      "        ],\n",
      "        [\n",
      "            \"smoke\\\\frame_vid6_240.jpg\",\n",
      "            0\n",
      "        ],\n",
      "        [\n",
      "            \"smoke\\\\frame_vid6_360.jpg\",\n",
      "            0\n",
      "        ],\n",
      "        [\n",
      "            \"smoke\\\\frame_vid6_480.jpg\",\n",
      "            0\n",
      "        ],\n",
      "        [\n",
      "            \"smoke\\\\frame_vid6_600.jpg\",\n",
      "            0\n",
      "        ],\n",
      "        [\n",
      "            \"non_smoke\\\\frame_vid7_0.jpg\",\n",
      "            1\n",
      "        ],\n",
      "        [\n",
      "            \"non_smoke\\\\frame_vid7_120.jpg\",\n",
      "            1\n",
      "        ],\n",
      "        [\n",
      "            \"non_smoke\\\\frame_vid7_240.jpg\",\n",
      "            1\n",
      "        ],\n",
      "        [\n",
      "            \"non_smoke\\\\frame_vid7_360.jpg\",\n",
      "            1\n",
      "        ],\n",
      "        [\n",
      "            \"non_smoke\\\\frame_vid7_480.jpg\",\n",
      "            1\n",
      "        ],\n",
      "        [\n",
      "            \"non_smoke\\\\frame_vid7_600.jpg\",\n",
      "            1\n",
      "        ],\n",
      "        [\n",
      "            \"non_smoke\\\\frame_vid7_720.jpg\",\n",
      "            1\n",
      "        ],\n",
      "        [\n",
      "            \"non_smoke\\\\frame_vid7_840.jpg\",\n",
      "            1\n",
      "        ]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Klasör yolu\n",
    "dataset_path = r\"C:\\Users\\VuralBayrakli\\gan\\new\"\n",
    "\n",
    "# Görüntülerin bulunduğu klasörler\n",
    "subfolders = [\"smoke\", \"non_smoke\"]\n",
    "\n",
    "# Etiketlerin tanımlandığı liste\n",
    "labels = []\n",
    "\n",
    "for label, subfolder in enumerate(subfolders):\n",
    "    subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "    image_files = os.listdir(subfolder_path)\n",
    "    for image_file in image_files:\n",
    "        # Etiket listesine görüntü dosyasının yolu ve etiketi ekleniyor\n",
    "        labels.append([os.path.join(subfolder, image_file), label])\n",
    "\n",
    "# JSON formatına dönüştürme\n",
    "import json\n",
    "\n",
    "data = {\"labels\": labels}\n",
    "\n",
    "# JSON verisini bir dosyaya kaydetmek isterseniz:\n",
    "with open(\"dataset.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "# JSON verisini ekrana yazdırmak isterseniz:\n",
    "print(json.dumps(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262eea19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"labels\": [[\"smoke\\\\frame_vid6_0.jpg\", 0], [\"smoke\\\\frame_vid6_120.jpg\", 0], [\"smoke\\\\frame_vid6_240.jpg\", 0], [\"smoke\\\\frame_vid6_360.jpg\", 0], [\"smoke\\\\frame_vid6_480.jpg\", 0], [\"smoke\\\\frame_vid6_600.jpg\", 0], [\"non_smoke\\\\frame_vid7_0.jpg\", 1], [\"non_smoke\\\\frame_vid7_120.jpg\", 1], [\"non_smoke\\\\frame_vid7_240.jpg\", 1], [\"non_smoke\\\\frame_vid7_360.jpg\", 1], [\"non_smoke\\\\frame_vid7_480.jpg\", 1], [\"non_smoke\\\\frame_vid7_600.jpg\", 1], [\"non_smoke\\\\frame_vid7_720.jpg\", 1], [\"non_smoke\\\\frame_vid7_840.jpg\", 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f70face9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VuralBayrakli\\gan\\stylegan2-ada-pytorch\\dataset_tool.py:205: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  resample = { 'box': PIL.Image.BOX, 'lanczos': PIL.Image.LANCZOS }[resize_filter]\n",
      "C:\\Users\\VuralBayrakli\\gan\\stylegan2-ada-pytorch\\dataset_tool.py:205: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resample = { 'box': PIL.Image.BOX, 'lanczos': PIL.Image.LANCZOS }[resize_filter]\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\n",
      " 29%|##8       | 4/14 [00:00<00:00, 31.39it/s]\n",
      " 57%|#####7    | 8/14 [00:00<00:00, 31.31it/s]\n",
      " 86%|########5 | 12/14 [00:00<00:00, 29.26it/s]\n",
      "100%|##########| 14/14 [00:00<00:00, 29.71it/s]\n"
     ]
    }
   ],
   "source": [
    "!python dataset_tool.py --source=\"C:\\Users\\VuralBayrakli\\gan\\new\" --dest=\"C:\\Users\\VuralBayrakli\\gan\\output\\dataset.zip\" --width=512 --height=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "551a3a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 50,\n",
      "  \"network_snapshot_ticks\": 50,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"random_seed\": 0,\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"C:\\\\Users\\\\VuralBayrakli\\\\gan\\\\output\\\\dataset.zip\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 14,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 512\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"num_workers\": 3,\n",
      "    \"prefetch_factor\": 2\n",
      "  },\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"synthesis_kwargs\": {\n",
      "      \"channel_base\": 32768,\n",
      "      \"channel_max\": 512,\n",
      "      \"num_fp16_res\": 4,\n",
      "      \"conv_clamp\": 256\n",
      "    }\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Discriminator\",\n",
      "    \"block_kwargs\": {},\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 6.5536\n",
      "  },\n",
      "  \"total_kimg\": 25000,\n",
      "  \"batch_size\": 8,\n",
      "  \"batch_gpu\": 8,\n",
      "  \"ema_kimg\": 2.5,\n",
      "  \"ema_rampup\": 0.05,\n",
      "  \"ada_target\": 0.6,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"run_dir\": \"C:\\\\Users\\\\VuralBayrakli\\\\gan\\\\training-runs\\\\00000-dataset-auto1\"\n",
      "}\n",
      "\n",
      "Output directory:   C:\\Users\\VuralBayrakli\\gan\\training-runs\\00000-dataset-auto1\n",
      "Training data:      C:\\Users\\VuralBayrakli\\gan\\output\\dataset.zip\n",
      "Training duration:  25000 kimg\n",
      "Number of GPUs:     1\n",
      "Number of images:   14\n",
      "Image resolution:   512\n",
      "Conditional model:  False\n",
      "Dataset x-flips:    False\n",
      "\n",
      "Dry run; exiting.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --outdir=\"C:\\Users\\VuralBayrakli\\gan\\training-runs\" --data=\"C:\\Users\\VuralBayrakli\\gan\\output\\dataset.zip\" --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e985b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
